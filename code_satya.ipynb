{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import calendar\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('network_backup_dataset.csv')\n",
    "dataset = dataset.drop(['Backup Time (hour)'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getX_Y_from_dataset(dataset):\n",
    "    Y = (dataset['Size of Backup (GB)'].as_matrix())\n",
    "    X = dataset.drop(['Size of Backup (GB)'],axis=1)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_day_names(days):\n",
    "    day_to_num = dict(zip(list(calendar.day_name), range(1, 8)))\n",
    "    return [day_to_num[day] for day in days]\n",
    "def encode_datalist(datalist):\n",
    "    encoding = {}\n",
    "    for i in datalist:\n",
    "        if i in encoding:\n",
    "            continue\n",
    "        else:\n",
    "            encoding[i] = i.split('_')[-1]\n",
    "    return [encoding[i] for i in datalist]\n",
    "def scalar_encode(dataset):\n",
    "    dataset_copy = dataset.copy()\n",
    "    # dataset_copy contains scalar encoding of features\n",
    "    dataset_copy['Day of Week'] = encode_day_names(dataset_copy['Day of Week'])\n",
    "    dataset_copy['File Name'] = encode_datalist(dataset_copy['File Name'])\n",
    "    dataset_copy['Work-Flow-ID'] = encode_datalist(dataset_copy['Work-Flow-ID'])\n",
    "    return dataset_copy\n",
    "\n",
    "    \n",
    "def one_hot_encode(dataset):\n",
    "    dataset_cat = dataset.select_dtypes(include=[object])\n",
    "    dataset_cat = scalar_encode(dataset_cat)\n",
    "    oh_enc = preprocessing.OneHotEncoder()\n",
    "    oh_enc.fit(dataset_cat)\n",
    "    onehotlabels = oh_enc.transform(dataset_cat)\n",
    "    cat_array = onehotlabels.toarray()\n",
    "    dataset_no_cat = dataset.select_dtypes(exclude=[object])\n",
    "    non_cat_array = dataset_no_cat.as_matrix()\n",
    "    return np.concatenate((non_cat_array,cat_array),axis = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_10fold(X,y,regressor):\n",
    "    kf = KFold(n_splits=10,shuffle = True,random_state = 42)\n",
    "    i = 1\n",
    "    bestModel = None\n",
    "    tr_e = 0\n",
    "    ts_e = 0\n",
    "    min_ts_e = 10\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        #print(\"Fold : \",i)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        regressor.fit(X_train,y_train)\n",
    "        train_preds = regressor.predict(X_train)\n",
    "        test_preds = regressor.predict(X_test)\n",
    "        test_error = mean_squared_error(y_test,test_preds)\n",
    "        tr_e += mean_squared_error(y_train,train_preds)\n",
    "        ts_e += test_error\n",
    "        if(test_error<min_ts_e):\n",
    "            min_ts_e = test_error\n",
    "            bestModel = regressor\n",
    "        i = i+1\n",
    "    return np.sqrt(tr_e/10),np.sqrt(ts_e/10), bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,Y= getX_Y_from_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =one_hot_encode(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyse_nn_regressor(layers,max_layer_size,interval):\n",
    "    train_map = defaultdict(list)\n",
    "    test_map = defaultdict(list)\n",
    "    for activation_ in ['identity', 'logistic', 'tanh', 'relu']:\n",
    "        print('activation function:',activation_)\n",
    "        for hidden_size in range(1,max_layer_size,interval):\n",
    "            mlp_reg = MLPRegressor(hidden_layer_sizes=tuple([hidden_size]*layers),activation=activation_,random_state=1)\n",
    "            train_rmses,test_rmses,m=perform_10fold(X,Y,mlp_reg)\n",
    "            print(train_rmses,test_rmses)\n",
    "            train_map[activation_].append(train_rmses)\n",
    "            test_map[activation_].append(test_rmses)\n",
    "    for algo in test_map:\n",
    "        plt.plot(range(1,max_layer_size,interval),test_map[algo], label = algo, marker='.',markersize=4)\n",
    "    plt.title('Neural Network Regression Performance | size : layers ='+str(layers))\n",
    "    plt.xlabel('Size of each layer')\n",
    "    plt.ylabel('Test RMSE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation function: identity\n",
      "0.0898448566956 0.0900431661475\n",
      "0.0899262903226 0.0901458635176\n",
      "0.0902705817951 0.0904654536543\n",
      "0.0898210283725 0.0899923300898\n",
      "0.089881983097 0.0900418516429\n",
      "0.0898582151076 0.0900491691642\n",
      "0.0898109598505 0.0899770914158\n",
      "0.0898005481209 0.0899501930242\n",
      "0.0914173733706 0.0914318256165\n",
      "0.0898579748263 0.0900766975813\n",
      "0.090226977646 0.0905892797625\n",
      "0.089894212014 0.0900831687463\n",
      "0.0899775829023 0.0901441386472\n",
      "0.0898213203609 0.0900056322279\n",
      "0.0898601015215 0.090057193675\n",
      "0.0910669889099 0.0914484699867\n",
      "0.0898269074348 0.0900363512197\n",
      "0.0898380999907 0.0900067341256\n",
      "0.0899394485891 0.0901395317742\n",
      "0.0899846039196 0.0902938456629\n",
      "0.0899802182389 0.0901558619676\n",
      "0.089886550868 0.0901116020153\n",
      "0.089962610626 0.0902204237087\n",
      "0.0899814248502 0.0900930237614\n",
      "0.08990801531 0.0902364562565\n",
      "0.0898683779741 0.0900266596789\n",
      "0.0898616405251 0.0900273491634\n",
      "0.0899027741122 0.0900942510256\n",
      "0.0907097472562 0.0909059186062\n",
      "0.0901339558172 0.0904156220144\n",
      "0.0900040619268 0.0902200669882\n",
      "0.0906489547713 0.0907325758713\n",
      "0.090171419146 0.0904285119802\n",
      "0.0900767460004 0.0902214596543\n",
      "0.0905241748875 0.0910126075835\n",
      "0.0899207973283 0.0901524350082\n",
      "0.0900574168247 0.0902210402185\n",
      "0.0908438541205 0.0912986603227\n",
      "0.089963308822 0.0902543557077\n",
      "0.0903893767853 0.0906106871665\n",
      "0.0909990301606 0.0915470003261\n",
      "0.0931257305567 0.0935540721314\n",
      "0.092491893901 0.0926917403398\n",
      "0.0900542467902 0.0903776844197\n",
      "0.0915054946811 0.091444795818\n",
      "0.0899770549891 0.0903186517666\n",
      "0.0924714148788 0.0930563484997\n",
      "0.0907018154193 0.0912417963389\n",
      "0.09015229139 0.0903246104586\n",
      "0.0906011455055 0.0906930925858\n",
      "0.0899014796265 0.0901024137981\n",
      "0.0910272561903 0.0911972458168\n",
      "0.0941725413059 0.0939507698781\n",
      "0.090200475483 0.0902209923474\n",
      "0.0903372780681 0.0904936227617\n",
      "0.0912700610765 0.0916144920515\n",
      "0.095076441606 0.0952019915313\n",
      "0.0915111805175 0.0918512878435\n",
      "0.0910889953557 0.0912375544587\n",
      "0.0907865176376 0.0909112031501\n",
      "0.0920621727929 0.0924960303218\n",
      "0.089953379123 0.0902295580579\n",
      "0.0904566997359 0.0907214469266\n",
      "0.0914234123901 0.0914898936677\n",
      "0.089973759795 0.0901196570248\n",
      "0.0915390558216 0.0918441757817\n",
      "0.0920164402514 0.0918379074186\n",
      "0.0900229970666 0.090256905549\n",
      "0.0899920837307 0.0901557174687\n",
      "0.0916199228999 0.091633455057\n",
      "0.0909840346267 0.0913075346085\n",
      "0.0983686551808 0.0981010273991\n",
      "0.0958275863441 0.0959829243411\n",
      "0.0909551266629 0.0908865735582\n",
      "0.0914561899978 0.0916775730894\n",
      "0.0926262321158 0.0930220860489\n",
      "0.0909934505871 0.0910711000579\n",
      "0.0932602467336 0.0929682110059\n",
      "0.0906216822756 0.0908088894912\n",
      "0.0903387213159 0.0906092348968\n",
      "0.0922782674345 0.0928328816753\n",
      "0.0904419109137 0.0907356213518\n",
      "0.0920350745847 0.0922983254837\n",
      "0.0943777852517 0.0947252101145\n",
      "0.0906524997612 0.0909293439207\n",
      "0.0946374381931 0.0948512013953\n",
      "0.0900843885081 0.0901647971337\n",
      "0.0959442497241 0.0964069210542\n",
      "0.0902994384616 0.0907676797848\n",
      "0.0905528821439 0.0907972062111\n",
      "0.0901220931703 0.0903437818278\n",
      "0.0919140691797 0.0922195053396\n",
      "0.0924024809308 0.0924000646426\n",
      "0.100109082871 0.100398542111\n",
      "0.0903839612661 0.0904198391732\n",
      "0.0909475439929 0.0908638983513\n",
      "0.0918342018229 0.0916845229203\n",
      "0.0909017213991 0.0913003277327\n",
      "0.0925481168507 0.0929993641622\n",
      "0.0935517767656 0.0939133113479\n",
      "activation function: logistic\n",
      "0.106826764215 0.106837889887\n",
      "0.0912039206306 0.0913755517176\n",
      "0.089987901769 0.0901402703771\n",
      "0.089287461866 0.0894894937688\n",
      "0.0892771269938 0.0894497926627\n",
      "0.0891487711949 0.0894036389105\n",
      "0.0896956245414 0.0898703867591\n",
      "0.0886629783309 0.0890033296663\n",
      "0.088585550282 0.0888599205915\n",
      "0.0884953397952 0.0885866240011\n",
      "0.0900042446294 0.0901917122372\n",
      "0.0894494108626 0.0896480057854\n",
      "0.0887431959905 0.0889570133337\n",
      "0.0893656341198 0.0895857413008\n",
      "0.0887176213409 0.0889515199446\n",
      "0.088481360395 0.0887601027584\n",
      "0.0888606406452 0.0890521275595\n",
      "0.0892720293198 0.0894933337584\n",
      "0.0899532948023 0.0901703373934\n",
      "0.0897405760668 0.0900199279882\n",
      "0.08888005426 0.089177328446\n",
      "0.0883629168656 0.08850561018\n",
      "0.0890674071056 0.0893509220081\n",
      "0.0892419573171 0.0894114705532\n",
      "0.0891223906172 0.0894829607824\n",
      "0.0885129086339 0.0886729541889\n",
      "0.0897321982001 0.0899400070375\n",
      "0.0891349187693 0.0893681422156\n",
      "0.089220199964 0.0894260590975\n",
      "0.0890975913464 0.0894195073666\n",
      "0.0890158832145 0.0892258497047\n",
      "0.088329527687 0.0885522728809\n",
      "0.0882278429408 0.0885164321777\n",
      "0.0886038190805 0.0887479238638\n",
      "0.0884601883551 0.0887055759516\n",
      "0.0886957895707 0.0890191198984\n",
      "0.0894114484935 0.0896267071047\n",
      "0.0884756630979 0.0888110027615\n",
      "0.0885762165138 0.0888013918305\n",
      "0.0887780303116 0.0889932382247\n",
      "0.0891858245332 0.0895045944793\n",
      "0.0887871777061 0.0890727919008\n",
      "0.0900409426082 0.0902288015719\n",
      "0.0890017568933 0.0891421590432\n",
      "0.0878805925798 0.0881429574926\n",
      "0.089100055649 0.089332684439\n",
      "0.0884255892097 0.0886554483682\n",
      "0.0889841575829 0.0892761948209\n",
      "0.0897121152069 0.0899379110341\n",
      "0.0893014223289 0.0895058169697\n",
      "0.0884672286352 0.0888695329837\n",
      "0.0889579226182 0.0892189807498\n",
      "0.0888871618802 0.0891402658733\n",
      "0.0893426909339 0.0894969504329\n",
      "0.0886312876291 0.0888670453176\n",
      "0.0890243941783 0.0893182695681\n",
      "0.0891200148987 0.089269497347\n",
      "0.0890347498137 0.089340738763\n",
      "0.0890302550929 0.089316788878\n",
      "0.0887600197183 0.0890991492715\n",
      "0.0892272599415 0.0894396182825\n",
      "0.0889635750405 0.0891907319814\n",
      "0.0890315586228 0.0892049491266\n",
      "0.0890939286778 0.0893048114981\n",
      "0.0883476738469 0.088641295056\n",
      "0.0890558479615 0.0893514316512\n",
      "0.0887172475117 0.0888512390832\n",
      "0.0890363169016 0.0894090113424\n",
      "0.0893494992442 0.0893939063666\n",
      "0.0890367944312 0.089405891868\n",
      "0.0894350769117 0.0895430093723\n",
      "0.0888547665878 0.089051817308\n",
      "0.0892614170785 0.0894425834315\n",
      "0.089259200048 0.08942685416\n",
      "0.089055971228 0.0891840807056\n",
      "0.088938857098 0.0891695304271\n",
      "0.0894260191982 0.0896605021922\n",
      "0.0887838199714 0.0889588793965\n",
      "0.0887185302481 0.0889569452939\n",
      "0.0894118618506 0.0897620554444\n",
      "0.090114525006 0.0902893964348\n",
      "0.089044714007 0.0893598303557\n",
      "0.0892755070337 0.0895783439741\n",
      "0.0893726703336 0.0896775326024\n",
      "0.089422659558 0.0896986663096\n",
      "0.0903122482082 0.0908461979757\n",
      "0.0890298654141 0.0893440975643\n",
      "0.0889736419653 0.0892659564314\n",
      "0.0901406042602 0.0906051200532\n",
      "0.0891096259759 0.0892597976693\n",
      "0.090024045442 0.0902774363333\n",
      "0.0895539432955 0.0896220428942\n",
      "0.0892923903669 0.0895540853617\n",
      "0.0903836350418 0.0909262552659\n",
      "0.0894796682913 0.0895888350733\n",
      "0.0893634330401 0.0896124811924\n",
      "0.0896118641779 0.0898269430859\n",
      "0.0893467522892 0.0896577338494\n",
      "0.0891217230194 0.0892935152354\n",
      "0.0900054185355 0.0903098257\n",
      "activation function: tanh\n",
      "0.106822011407 0.106861417743\n",
      "0.090404466254 0.0906988363445\n",
      "0.0967592887837 0.0972037779653\n",
      "0.0910574177405 0.091630600981\n",
      "0.0900953373529 0.0906935832149\n",
      "0.0934103437847 0.094028792801\n",
      "0.0909533492108 0.0917546614547\n",
      "0.0895392215465 0.0901086359558\n",
      "0.0867294644683 0.0873754633124\n",
      "0.0906807589216 0.0913886423056\n",
      "0.0671645587769 0.0694320949141\n",
      "0.0682686285172 0.070289408979\n",
      "0.0559660458647 0.0573933536653\n",
      "0.0880461521902 0.0888393941345\n",
      "0.0564209755942 0.0577415765818\n",
      "0.0554623712651 0.0570285739569\n",
      "0.0769551785929 0.0781504789331\n",
      "0.0875555868961 0.08851563566\n",
      "0.0575987833228 0.0589674583528\n",
      "0.0528528382607 0.054464632952\n",
      "0.0525484077271 0.0538358280715\n",
      "0.0869230158727 0.0878106785487\n",
      "0.05650258011 0.0580034229968\n",
      "0.0587031867741 0.0600206894848\n",
      "0.0538419717512 0.05532266796\n",
      "0.0551641400753 0.0566079801145\n",
      "0.0572348903494 0.0582165123815\n",
      "0.0796519975258 0.0799016683054\n",
      "0.0544279262659 0.0556874499674\n",
      "0.0567580599406 0.0584554292539\n",
      "0.0850725289745 0.0859950968906\n",
      "0.0555242662646 0.056832639516\n",
      "0.0637857972325 0.0665767187427\n",
      "0.0519087925974 0.0532078072095\n",
      "0.0515550425655 0.052753381081\n",
      "0.0844208814032 0.0852013432064\n",
      "0.0532318470697 0.0545814942632\n",
      "0.0505901512886 0.0517747369986\n",
      "0.0864508753206 0.0873478872282\n",
      "0.0508804318426 0.0523449712302\n",
      "0.0512753717214 0.0525989073338\n",
      "0.0507001948076 0.0520315800194\n",
      "0.0518276682627 0.0532080141779\n",
      "0.0522446086914 0.0535114747817\n",
      "0.0496971007809 0.0509481991494\n",
      "0.085911571776 0.0867866508388\n",
      "0.0508674753247 0.0522499456053\n",
      "0.0509804092205 0.0524117454757\n",
      "0.0823869515271 0.083235618385\n",
      "0.0493805801149 0.0507954347505\n",
      "0.0855759879201 0.0862713901438\n",
      "0.0724487999812 0.0744059267541\n",
      "0.0499000673242 0.0514827166191\n",
      "0.0786991719001 0.0789879729329\n",
      "0.0748978236882 0.0746077146175\n",
      "0.0491311789458 0.0505336215923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0516370032147 0.0531586137543\n",
      "0.049743430599 0.05109536252\n",
      "0.0499887170704 0.0513525931248\n",
      "0.0507176305718 0.0520158074968\n",
      "0.0508568445424 0.0520027485862\n",
      "0.083364902813 0.0841816120803\n",
      "0.050770575578 0.0524172036338\n",
      "0.0513833825679 0.052635276511\n",
      "0.0779654266198 0.0801611453748\n",
      "0.0515419535873 0.0528729365213\n",
      "0.0514600027786 0.0527744946127\n",
      "0.0746716837128 0.0766382385089\n",
      "0.0840287174528 0.0848134269118\n",
      "0.0502494943653 0.0515657390736\n",
      "0.0531603412334 0.0544393390046\n",
      "0.0522754092055 0.0537868344231\n",
      "0.0510333782633 0.0523130694054\n",
      "0.0516866683845 0.0530992478404\n",
      "0.0513639736752 0.0524641064686\n",
      "0.0500962996429 0.0516479409999\n",
      "0.0506256849448 0.0518371798396\n",
      "0.0526431534717 0.053963964991\n",
      "0.052008629036 0.0533866666858\n",
      "0.083227321755 0.0841375136779\n",
      "0.0511250712341 0.0523676841187\n",
      "0.0653408348285 0.0657366634803\n",
      "0.0512857306628 0.0523165465287\n",
      "0.0515819020009 0.0528165179556\n",
      "0.0507450961229 0.0517779336301\n",
      "0.053177827595 0.0542922291869\n",
      "0.0808581866453 0.0814965563946\n"
     ]
    }
   ],
   "source": [
    "analyse_nn_regressor(1,200,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation function: identity\n",
      "0.0723762566094 0.0725763577688\n",
      "0.0718288159377 0.071945034621\n",
      "0.0762881112378 0.0764434642414\n",
      "0.0715618348201 0.0717788760484\n",
      "0.071492170745 0.0717098789875\n",
      "0.0714892844189 0.071714415104\n",
      "0.0716843830978 0.0719999198473\n",
      "0.0715426557765 0.071769593634\n",
      "0.0714931730582 0.0716908873776\n",
      "0.0714480829977 0.0716134445329\n",
      "0.0721235435723 0.0721203639803\n",
      "0.0717189680393 0.0718752745359\n",
      "0.07159845885 0.0717108890534\n",
      "0.0719851138223 0.0723481669648\n",
      "0.0717980531202 0.0719200688914\n",
      "0.0717661848208 0.0719403048752\n",
      "0.0722232628418 0.0723641633245\n",
      "0.0718449489492 0.0720414434774\n",
      "0.0718708243205 0.0722222757101\n",
      "0.0748660689612 0.0748988015291\n",
      "0.0718452051819 0.0720192939819\n",
      "0.0726202723131 0.0727661338194\n",
      "0.0719315571468 0.0720737370501\n",
      "0.0718228551775 0.0719637303051\n",
      "0.0716872091928 0.0718891691885\n",
      "0.0736352381209 0.0737391667073\n",
      "0.0722238578693 0.0724427234986\n",
      "0.0718474514015 0.0720175714785\n",
      "0.0718610655766 0.0720826816264\n",
      "0.0738965249576 0.0743614903527\n",
      "0.0714831289084 0.0716566547272\n",
      "0.072861841443 0.0730845994282\n",
      "0.0724414698 0.0727518303932\n",
      "0.0725871340516 0.0728864140683\n",
      "0.0765689029456 0.0769065713489\n",
      "0.0741595311984 0.0744658056312\n",
      "0.0720440177448 0.0722708741411\n",
      "0.0716571098468 0.0717740524793\n",
      "0.0721822659591 0.0723812819727\n",
      "0.0720426802068 0.0721887941175\n",
      "0.0757442611624 0.0757643530523\n",
      "0.0733005847233 0.073352785657\n",
      "0.0726548193909 0.0728620204488\n",
      "0.0728703021263 0.0730782357619\n",
      "0.0727749191519 0.0728308087081\n",
      "0.0737200734344 0.0738351176957\n",
      "0.0762202394702 0.0761361460567\n",
      "0.0725716677537 0.0727886271341\n",
      "0.073885505603 0.0741558704948\n",
      "0.0727073143103 0.0728353694169\n",
      "activation function: logistic\n"
     ]
    }
   ],
   "source": [
    "analyse_nn_regressor(2,100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyse_nn_regressor(3,50,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyse_nn_regressor(5,20,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_knn(neighbor_range,remove_cols=[]):\n",
    "    removed_data = dataset.drop(remove_cols,axis=1)\n",
    "    X_r,Y_r = getX_Y_from_dataset(removed_data)\n",
    "    X_r = one_hot_encode(X_r)\n",
    "    errors = []\n",
    "\n",
    "    for neighbors in neighbor_range:\n",
    "        print(\"Neighbors:\",neighbors)\n",
    "        knn_model = KNeighborsRegressor(n_neighbors = neighbors )\n",
    "        tr,ts,m = perform_10fold(X_r,Y_r,knn_model)\n",
    "        errors.append(ts)\n",
    "    plt.title('KNN Regression Performance excluding columns '+str(remove_cols))\n",
    "    plt.xlabel('Neighbors')\n",
    "    plt.ylabel('Test RMSE Error')\n",
    "    plt.plot(neighbor_range,errors,marker='.',markersize=4)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyze_knn(range(2,100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyze_knn(range(2,100,2),['Week #','File Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workflows = list(set(dataset['Work-Flow-ID'].values))\n",
    "workflow_datasets=[dataset.loc[dataset['Work-Flow-ID'] == x] for x in  workflows]\n",
    "workflow_datasets_xy = [getX_Y_from_dataset(d) for d in workflow_datasets] \n",
    "workflow_datasets_xy_oh = [(one_hot_encode(x[0]),x[1]) for x in workflow_datasets_xy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Part 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workflow_datasets_xy_oh = [(scalar_encode(x[0]),x[1]) for x in workflow_datasets_xy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_graph(x,y,xlabel,ylabel,title):\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.scatter(x, y, color='blue', lw=1, label=y,s=3)\n",
    "    #plt.plot([y.min(), y.max()], [0,0], 'k--', lw=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_graph_time(y1,y2,y1label,y2label,ylabel,title):\n",
    "    plt.title(title)\n",
    "    plt.scatter(np.arange(y1.shape[0]), y1, color='blue', label=y1label,s=3)\n",
    "    plt.scatter(np.arange(y1.shape[0]), y2, color='red', label=y2label,s=3)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyse_lin_reg_separate(plots=False):\n",
    "    i = 0\n",
    "    for x in workflow_datasets_xy_oh:\n",
    "        print(workflows[i])\n",
    "        i+=1\n",
    "        regressor = LinearRegression()\n",
    "        avg_tr,avg_ts,bestModel = perform_10fold(x[0],x[1],regressor)\n",
    "        print(\"------------------------------\")\n",
    "        print(\"Average Training RMSE : \",avg_tr)\n",
    "        print(\"Average Test RMSE : \",avg_ts)\n",
    "        predicted = bestModel.predict(x[0])\n",
    "        if(plots):\n",
    "            plot_graph(x[1],predicted,\"Actual\",\"Fitted\",\"Fitted vs Actual\")\n",
    "            plot_graph_time(x[1],predicted,\"Actual\",\"Fitted\",\"Actual and Fitted values\",\"Actual and Fitted values over time\")\n",
    "            plot_graph(predicted,x[1]-predicted,\"Fitted\",\"Residual\",\"Residual vs Fitted\")\n",
    "            plot_graph_time(x[1]-predicted,predicted,\"Residual\",\"Fitted\",\"Residual and Fitted values\",\"Residual and Fitted values over time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyse_poly_lin_reg_separate(plots=False,poly_degrees = []):\n",
    "    i = 0\n",
    "    test_rm = defaultdict(list)\n",
    "    train_rm= defaultdict(list)\n",
    "    best_deg_map = {}\n",
    "    for x in workflow_datasets_xy_oh:\n",
    "        print(\"****************************\")\n",
    "        print(workflows[i])        \n",
    "        best_ts = 10000\n",
    "        best_model = None\n",
    "        best_deg = -1\n",
    "        best_poly = None\n",
    "        for deg in poly_degrees:\n",
    "            regressor = LinearRegression()\n",
    "            poly = PolynomialFeatures(deg)\n",
    "            x_ = poly.fit_transform(x[0])\n",
    "            avg_tr,avg_ts,bestModel = perform_10fold(x_,x[1],regressor)\n",
    "            test_rm[workflows[i]].append(avg_ts)\n",
    "            train_rm[workflows[i]].append(avg_ts)\n",
    "            print(\"average Training RMSE : \",avg_tr)\n",
    "            print(\"average Test RMSE : \",avg_ts)\n",
    "            if(avg_ts<=best_ts):\n",
    "                best_ts = avg_ts\n",
    "                best_model = bestModel\n",
    "                best_deg = deg\n",
    "                best_poly = poly\n",
    "                print('best so far',deg)\n",
    "        x_tot = best_poly.transform(x[0])\n",
    "        predicted = best_model.predict(x_tot)\n",
    "        best_deg_map[workflows[i]]=best_deg\n",
    "        if(plots):\n",
    "            plot_graph(x[1],predicted,\"Actual\",\"Fitted\",str(workflows[i])+\" Fitted vs Actual\")\n",
    "            plot_graph_time(x[1],predicted,\"Actual\",\"Fitted\",\"Actual and Fitted values\",str(workflows[i])+\" Actual and Fitted values over time\")\n",
    "            plot_graph(predicted,x[1]-predicted,\"Fitted\",\"Residual\",str(workflows[i])+\" Residual vs Fitted\")\n",
    "            plot_graph_time(x[1]-predicted,predicted,\"Residual\",\"Fitted\",\"Residual and Fitted values\",str(workflows[i])+\" Residual and Fitted values over time\")\n",
    "        i+=1\n",
    "    print(best_deg)\n",
    "    for x in workflows:\n",
    "        plt.plot(poly_degrees,test_rm[x], label = x, marker='.',markersize=4)\n",
    "    plt.title('Avg Test RMSE Vs Polynomial Degree')\n",
    "    plt.xlabel('Degree of Polynomial')\n",
    "    plt.ylabel('Test RMSE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    for x in workflows:\n",
    "        plt.plot(poly_degrees,train_rm[x], label = x, marker='.',markersize=4)\n",
    "    plt.title('Avg Train RMSE Vs Polynomial Degree')\n",
    "    plt.xlabel('Degree of Polynomial')\n",
    "    plt.ylabel('Train RMSE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyse_poly_lin_reg_separate(poly_degrees=[2,3,4,5,6,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
